{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras \nfrom tqdm import tqdm\nfrom keras.layers import Dense\nimport json \nimport re\nimport string\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport unicodedata\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.229470Z","iopub.execute_input":"2023-08-16T10:26:52.230126Z","iopub.status.idle":"2023-08-16T10:26:52.238394Z","shell.execute_reply.started":"2023-08-16T10:26:52.230066Z","shell.execute_reply":"2023-08-16T10:26:52.237424Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"question  =[]\nanswer = []\nwith open(\"../input/simple-dialogs-for-chatbot/dialogs.txt\",'r') as f :\n    for line in f :\n        line  =  line.split('\\t')\n        question.append(line[0])\n        answer.append(line[1])\nprint(len(question) == len(answer))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.240592Z","iopub.execute_input":"2023-08-16T10:26:52.241102Z","iopub.status.idle":"2023-08-16T10:26:52.258500Z","shell.execute_reply.started":"2023-08-16T10:26:52.241060Z","shell.execute_reply":"2023-08-16T10:26:52.257660Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"question[:5]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.259982Z","iopub.execute_input":"2023-08-16T10:26:52.260669Z","iopub.status.idle":"2023-08-16T10:26:52.267042Z","shell.execute_reply.started":"2023-08-16T10:26:52.260635Z","shell.execute_reply":"2023-08-16T10:26:52.266104Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"['hi, how are you doing?',\n \"i'm fine. how about yourself?\",\n \"i'm pretty good. thanks for asking.\",\n 'no problem. so how have you been?',\n \"i've been great. what about you?\"]"},"metadata":{}}]},{"cell_type":"code","source":"answer[:5]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.269865Z","iopub.execute_input":"2023-08-16T10:26:52.270663Z","iopub.status.idle":"2023-08-16T10:26:52.277444Z","shell.execute_reply.started":"2023-08-16T10:26:52.270599Z","shell.execute_reply":"2023-08-16T10:26:52.276406Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[\"i'm fine. how about yourself?\\n\",\n \"i'm pretty good. thanks for asking.\\n\",\n 'no problem. so how have you been?\\n',\n \"i've been great. what about you?\\n\",\n \"i've been good. i'm in school right now.\\n\"]"},"metadata":{}}]},{"cell_type":"code","source":"answer = [ i.replace(\"\\n\",\"\") for i in answer]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.278969Z","iopub.execute_input":"2023-08-16T10:26:52.280020Z","iopub.status.idle":"2023-08-16T10:26:52.294224Z","shell.execute_reply.started":"2023-08-16T10:26:52.279985Z","shell.execute_reply":"2023-08-16T10:26:52.293242Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"answer[:5]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.295754Z","iopub.execute_input":"2023-08-16T10:26:52.296479Z","iopub.status.idle":"2023-08-16T10:26:52.305656Z","shell.execute_reply.started":"2023-08-16T10:26:52.296446Z","shell.execute_reply":"2023-08-16T10:26:52.304628Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"[\"i'm fine. how about yourself?\",\n \"i'm pretty good. thanks for asking.\",\n 'no problem. so how have you been?',\n \"i've been great. what about you?\",\n \"i've been good. i'm in school right now.\"]"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.DataFrame({\"question\" : question ,\"answer\":answer})\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.307144Z","iopub.execute_input":"2023-08-16T10:26:52.308227Z","iopub.status.idle":"2023-08-16T10:26:52.322131Z","shell.execute_reply.started":"2023-08-16T10:26:52.308148Z","shell.execute_reply":"2023-08-16T10:26:52.320993Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"                              question  \\\n0               hi, how are you doing?   \n1        i'm fine. how about yourself?   \n2  i'm pretty good. thanks for asking.   \n3    no problem. so how have you been?   \n4     i've been great. what about you?   \n\n                                     answer  \n0             i'm fine. how about yourself?  \n1       i'm pretty good. thanks for asking.  \n2         no problem. so how have you been?  \n3          i've been great. what about you?  \n4  i've been good. i'm in school right now.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hi, how are you doing?</td>\n      <td>i'm fine. how about yourself?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i'm fine. how about yourself?</td>\n      <td>i'm pretty good. thanks for asking.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i'm pretty good. thanks for asking.</td>\n      <td>no problem. so how have you been?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>no problem. so how have you been?</td>\n      <td>i've been great. what about you?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i've been great. what about you?</td>\n      <td>i've been good. i'm in school right now.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def unicode_to_ascii(s):\n    return ''.join(c for c in unicodedata.normalize('NFD', s)\n      if unicodedata.category(c) != 'Mn')","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.323721Z","iopub.execute_input":"2023-08-16T10:26:52.324926Z","iopub.status.idle":"2023-08-16T10:26:52.330994Z","shell.execute_reply.started":"2023-08-16T10:26:52.324887Z","shell.execute_reply":"2023-08-16T10:26:52.329939Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    text = unicode_to_ascii(text.lower().strip())\n    text = re.sub(r\"i'm\", \"i am\", text)\n    text = re.sub(r\"\\r\", \"\", text)\n    text = re.sub(r\"he's\", \"he is\", text)\n    text = re.sub(r\"she's\", \"she is\", text)\n    text = re.sub(r\"it's\", \"it is\", text)\n    text = re.sub(r\"that's\", \"that is\", text)\n    text = re.sub(r\"what's\", \"that is\", text)\n    text = re.sub(r\"where's\", \"where is\", text)\n    text = re.sub(r\"how's\", \"how is\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"won't\", \"will not\", text)\n    text = re.sub(r\"can't\", \"cannot\", text)\n    text = re.sub(r\"n't\", \" not\", text)\n    text = re.sub(r\"n'\", \"ng\", text)\n    text = re.sub(r\"'bout\", \"about\", text)\n    text = re.sub(r\"'til\", \"until\", text)\n    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n    text = text.translate(str.maketrans('', '', string.punctuation)) \n    text = re.sub(\"(\\\\W)\",\" \",text) \n    text = re.sub('\\S*\\d\\S*\\s*','', text)\n    text =  \"<sos> \" +  text + \" <eos>\"\n    return text\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.332638Z","iopub.execute_input":"2023-08-16T10:26:52.333379Z","iopub.status.idle":"2023-08-16T10:26:52.346384Z","shell.execute_reply.started":"2023-08-16T10:26:52.333345Z","shell.execute_reply":"2023-08-16T10:26:52.345385Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"data[\"question\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.435358Z","iopub.execute_input":"2023-08-16T10:26:52.438924Z","iopub.status.idle":"2023-08-16T10:26:52.447430Z","shell.execute_reply.started":"2023-08-16T10:26:52.438871Z","shell.execute_reply":"2023-08-16T10:26:52.446289Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'hi, how are you doing?'"},"metadata":{}}]},{"cell_type":"code","source":"data[\"question\"] = data.question.apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.453510Z","iopub.execute_input":"2023-08-16T10:26:52.458475Z","iopub.status.idle":"2023-08-16T10:26:52.775763Z","shell.execute_reply.started":"2023-08-16T10:26:52.458378Z","shell.execute_reply":"2023-08-16T10:26:52.774693Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"data[\"question\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.777083Z","iopub.execute_input":"2023-08-16T10:26:52.782932Z","iopub.status.idle":"2023-08-16T10:26:52.792522Z","shell.execute_reply.started":"2023-08-16T10:26:52.782895Z","shell.execute_reply":"2023-08-16T10:26:52.791616Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'<sos> hi how are you doing <eos>'"},"metadata":{}}]},{"cell_type":"code","source":"data[\"answer\"] = data.answer.apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:52.796084Z","iopub.execute_input":"2023-08-16T10:26:52.796748Z","iopub.status.idle":"2023-08-16T10:26:53.099242Z","shell.execute_reply.started":"2023-08-16T10:26:52.796714Z","shell.execute_reply":"2023-08-16T10:26:53.098192Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"question  = data.question.values.tolist()\nanswer =  data.answer.values.tolist()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.109145Z","iopub.execute_input":"2023-08-16T10:26:53.109893Z","iopub.status.idle":"2023-08-16T10:26:53.117632Z","shell.execute_reply.started":"2023-08-16T10:26:53.109847Z","shell.execute_reply":"2023-08-16T10:26:53.116587Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def tokenize(lang):\n    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n      filters='')\n    lang_tokenizer.fit_on_texts(lang)\n    tensor = lang_tokenizer.texts_to_sequences(lang)\n\n    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n                                                         padding='post')\n\n    return tensor, lang_tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.119306Z","iopub.execute_input":"2023-08-16T10:26:53.120040Z","iopub.status.idle":"2023-08-16T10:26:53.130256Z","shell.execute_reply.started":"2023-08-16T10:26:53.119997Z","shell.execute_reply":"2023-08-16T10:26:53.129263Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"input_tensor , inp_lang  =  tokenize(question)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.132224Z","iopub.execute_input":"2023-08-16T10:26:53.133230Z","iopub.status.idle":"2023-08-16T10:26:53.284775Z","shell.execute_reply.started":"2023-08-16T10:26:53.133165Z","shell.execute_reply":"2023-08-16T10:26:53.283797Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"target_tensor , targ_lang  =  tokenize(answer)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.286131Z","iopub.execute_input":"2023-08-16T10:26:53.286801Z","iopub.status.idle":"2023-08-16T10:26:53.430856Z","shell.execute_reply.started":"2023-08-16T10:26:53.286765Z","shell.execute_reply":"2023-08-16T10:26:53.429852Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":" #len(inp_question) ==  len(inp_answer)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.432185Z","iopub.execute_input":"2023-08-16T10:26:53.433091Z","iopub.status.idle":"2023-08-16T10:26:53.437493Z","shell.execute_reply.started":"2023-08-16T10:26:53.433053Z","shell.execute_reply":"2023-08-16T10:26:53.436441Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def remove_tags(sentence):\n    return sentence.split(\"<start>\")[-1].split(\"<end>\")[0]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.438961Z","iopub.execute_input":"2023-08-16T10:26:53.439600Z","iopub.status.idle":"2023-08-16T10:26:53.448507Z","shell.execute_reply.started":"2023-08-16T10:26:53.439556Z","shell.execute_reply":"2023-08-16T10:26:53.447447Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.450367Z","iopub.execute_input":"2023-08-16T10:26:53.451007Z","iopub.status.idle":"2023-08-16T10:26:53.460810Z","shell.execute_reply.started":"2023-08-16T10:26:53.450973Z","shell.execute_reply":"2023-08-16T10:26:53.459763Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Creating training and validation sets using an 80-20 split\ninput_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.462415Z","iopub.execute_input":"2023-08-16T10:26:53.463029Z","iopub.status.idle":"2023-08-16T10:26:53.473379Z","shell.execute_reply.started":"2023-08-16T10:26:53.462996Z","shell.execute_reply":"2023-08-16T10:26:53.472289Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"#print(len(train_inp) , len(val_inp) , len(train_target) , len(val_target))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.475887Z","iopub.execute_input":"2023-08-16T10:26:53.476813Z","iopub.status.idle":"2023-08-16T10:26:53.488978Z","shell.execute_reply.started":"2023-08-16T10:26:53.476775Z","shell.execute_reply":"2023-08-16T10:26:53.487947Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"BUFFER_SIZE = len(input_tensor_train)\nBATCH_SIZE = 64\nsteps_per_epoch = len(input_tensor_train)//BATCH_SIZE\nembedding_dim = 256\nunits = 1024\nvocab_inp_size = len(inp_lang.word_index)+1\nvocab_tar_size = len(targ_lang.word_index)+1\n\ndataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\ndataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n\nexample_input_batch, example_target_batch = next(iter(dataset))\nexample_input_batch.shape, example_target_batch.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.495361Z","iopub.execute_input":"2023-08-16T10:26:53.495979Z","iopub.status.idle":"2023-08-16T10:26:53.547112Z","shell.execute_reply.started":"2023-08-16T10:26:53.495943Z","shell.execute_reply":"2023-08-16T10:26:53.546226Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"(TensorShape([64, 22]), TensorShape([64, 22]))"},"metadata":{}}]},{"cell_type":"code","source":"class Encoder(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n        super(Encoder, self).__init__()\n        self.batch_sz = batch_sz\n        self.enc_units = enc_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru = tf.keras.layers.GRU(self.enc_units,\n                                       return_sequences=True,\n                                       return_state=True,\n                                       recurrent_initializer='glorot_uniform')\n\n    def call(self, x,hidden):\n        x = self.embedding(x)\n        output, state = self.gru(x, initial_state = hidden)\n        return output, state\n    \n    def initialize_hidden_state(self):\n        return tf.zeros((self.batch_sz, self.enc_units))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.550964Z","iopub.execute_input":"2023-08-16T10:26:53.553170Z","iopub.status.idle":"2023-08-16T10:26:53.564069Z","shell.execute_reply.started":"2023-08-16T10:26:53.553133Z","shell.execute_reply":"2023-08-16T10:26:53.563028Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n\n# sample input\nsample_hidden = encoder.initialize_hidden_state()\nsample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\nprint ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\nprint ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.565635Z","iopub.execute_input":"2023-08-16T10:26:53.566264Z","iopub.status.idle":"2023-08-16T10:26:53.613261Z","shell.execute_reply.started":"2023-08-16T10:26:53.566229Z","shell.execute_reply":"2023-08-16T10:26:53.612384Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Encoder output shape: (batch size, sequence length, units) (64, 22, 1024)\nEncoder Hidden state shape: (batch size, units) (64, 1024)\n","output_type":"stream"}]},{"cell_type":"code","source":"class BahdanauAttention(tf.keras.layers.Layer):\n    def __init__(self, units):\n        super(BahdanauAttention, self).__init__()\n        self.W1 = tf.keras.layers.Dense(units)\n        self.W2 = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n\n    def call(self, query, values):\n        # query hidden state shape == (batch_size, hidden size)\n        # query_with_time_axis shape == (batch_size, 1, hidden size)\n        # values shape == (batch_size, max_len, hidden size)\n        # we are doing this to broadcast addition along the time axis to calculate the score\n        query_with_time_axis = tf.expand_dims(query, 1)\n\n        # score shape == (batch_size, max_length, 1)\n        # we get 1 at the last axis because we are applying score to self.V\n        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n        score = self.V(tf.nn.tanh(\n            self.W1(query_with_time_axis) + self.W2(values)))\n\n        # attention_weights shape == (batch_size, max_length, 1)\n        attention_weights = tf.nn.softmax(score, axis=1)\n\n        # context_vector shape after sum == (batch_size, hidden_size)\n        context_vector = attention_weights * values\n        context_vector = tf.reduce_sum(context_vector, axis=1)\n\n        return context_vector, attention_weights","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.617441Z","iopub.execute_input":"2023-08-16T10:26:53.619674Z","iopub.status.idle":"2023-08-16T10:26:53.632651Z","shell.execute_reply.started":"2023-08-16T10:26:53.619616Z","shell.execute_reply":"2023-08-16T10:26:53.631457Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"attention_layer = BahdanauAttention(10)\nattention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n\nprint(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\nprint(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.638726Z","iopub.execute_input":"2023-08-16T10:26:53.641715Z","iopub.status.idle":"2023-08-16T10:26:53.681141Z","shell.execute_reply.started":"2023-08-16T10:26:53.641674Z","shell.execute_reply":"2023-08-16T10:26:53.680169Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Attention result shape: (batch size, units) (64, 1024)\nAttention weights shape: (batch_size, sequence_length, 1) (64, 22, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n        super(Decoder, self).__init__()\n        self.batch_sz = batch_sz\n        self.dec_units = dec_units\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru = tf.keras.layers.GRU(self.dec_units,\n                                       return_sequences=True,\n                                       return_state=True,\n                                       recurrent_initializer='glorot_uniform')\n        self.fc = tf.keras.layers.Dense(vocab_size)\n\n        # used for attention\n        self.attention = BahdanauAttention(self.dec_units)\n\n    def call(self, x, hidden, enc_output):\n        # enc_output shape == (batch_size, max_length, hidden_size)\n        context_vector, attention_weights = self.attention(hidden, enc_output)\n\n        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n        x = self.embedding(x)\n\n        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n\n        # passing the concatenated vector to the GRU\n        output, state = self.gru(x)\n\n        # output shape == (batch_size * 1, hidden_size)\n        output = tf.reshape(output, (-1, output.shape[2]))\n\n        # output shape == (batch_size, vocab)\n        x = self.fc(output)\n\n        return x, state, attention_weights\n","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.685412Z","iopub.execute_input":"2023-08-16T10:26:53.687793Z","iopub.status.idle":"2023-08-16T10:26:53.701891Z","shell.execute_reply.started":"2023-08-16T10:26:53.687752Z","shell.execute_reply":"2023-08-16T10:26:53.700638Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n\nsample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n                                      sample_hidden, sample_output)\n\nprint ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.707251Z","iopub.execute_input":"2023-08-16T10:26:53.710125Z","iopub.status.idle":"2023-08-16T10:26:53.781955Z","shell.execute_reply.started":"2023-08-16T10:26:53.710086Z","shell.execute_reply":"2023-08-16T10:26:53.780959Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Decoder output shape: (batch_size, vocab size) (64, 2347)\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam()\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n\n    return tf.reduce_mean(loss_)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.783222Z","iopub.execute_input":"2023-08-16T10:26:53.783809Z","iopub.status.idle":"2023-08-16T10:26:53.801117Z","shell.execute_reply.started":"2023-08-16T10:26:53.783772Z","shell.execute_reply":"2023-08-16T10:26:53.799988Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(inp, targ, enc_hidden):\n    loss = 0\n\n    with tf.GradientTape() as tape:\n        enc_output, enc_hidden = encoder(inp, enc_hidden)\n\n        dec_hidden = enc_hidden\n\n        dec_input = tf.expand_dims([targ_lang.word_index['<sos>']] * BATCH_SIZE, 1)\n\n        # Teacher forcing - feeding the target as the next input\n        for t in range(1, targ.shape[1]):\n            # passing enc_output to the decoder\n            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n\n            loss += loss_function(targ[:, t], predictions)\n\n            # using teacher forcing\n            dec_input = tf.expand_dims(targ[:, t], 1)\n\n    batch_loss = (loss / int(targ.shape[1]))\n\n    variables = encoder.trainable_variables + decoder.trainable_variables\n\n    gradients = tape.gradient(loss, variables)\n\n    optimizer.apply_gradients(zip(gradients, variables))\n\n    return batch_loss","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.803130Z","iopub.execute_input":"2023-08-16T10:26:53.804135Z","iopub.status.idle":"2023-08-16T10:26:53.815038Z","shell.execute_reply.started":"2023-08-16T10:26:53.804097Z","shell.execute_reply":"2023-08-16T10:26:53.813898Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 40\n\nfor epoch in tqdm(range(1, EPOCHS + 1), desc='Epochs', unit='epoch'):\n    enc_hidden = encoder.initialize_hidden_state()\n    total_loss = 0\n\n    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n        batch_loss = train_step(inp, targ, enc_hidden)\n        total_loss += batch_loss\n\n    if epoch % 4 == 0:\n        print('Epoch:{:3d} Loss:{:.4f}'.format(epoch, total_loss / steps_per_epoch))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:26:53.817305Z","iopub.execute_input":"2023-08-16T10:26:53.818212Z","iopub.status.idle":"2023-08-16T10:30:49.723448Z","shell.execute_reply.started":"2023-08-16T10:26:53.818156Z","shell.execute_reply":"2023-08-16T10:30:49.722434Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stderr","text":"Epochs:  10%|█         | 4/40 [00:59<06:29, 10.83s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch:  4 Loss:1.5809\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  20%|██        | 8/40 [01:20<03:19,  6.24s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch:  8 Loss:1.3380\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  30%|███       | 12/40 [01:40<02:29,  5.35s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch: 12 Loss:1.1543\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  40%|████      | 16/40 [02:00<02:03,  5.13s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch: 16 Loss:0.9981\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  50%|█████     | 20/40 [02:20<01:38,  4.91s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch: 20 Loss:0.8397\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  60%|██████    | 24/40 [02:39<01:17,  4.86s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch: 24 Loss:0.6541\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  70%|███████   | 28/40 [02:58<00:57,  4.81s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch: 28 Loss:0.4608\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  80%|████████  | 32/40 [03:17<00:38,  4.82s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch: 32 Loss:0.2627\n","output_type":"stream"},{"name":"stderr","text":"Epochs:  90%|█████████ | 36/40 [03:36<00:19,  4.78s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch: 36 Loss:0.1221\n","output_type":"stream"},{"name":"stderr","text":"Epochs: 100%|██████████| 40/40 [03:55<00:00,  5.90s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch: 40 Loss:0.0597\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(sentence):\n    sentence = clean_text(sentence)\n\n    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n                                                         maxlen=max_length_inp,\n                                                         padding='post')\n    inputs = tf.convert_to_tensor(inputs)\n\n    result = ''\n\n    hidden = [tf.zeros((1, units))]\n    enc_out, enc_hidden = encoder(inputs, hidden)\n\n    dec_hidden = enc_hidden\n    dec_input = tf.expand_dims([targ_lang.word_index['<sos>']], 0)\n\n    for t in range(max_length_targ):\n        predictions, dec_hidden, attention_weights = decoder(dec_input,\n                                                             dec_hidden,\n                                                             enc_out)\n\n        # storing the attention weights to plot later on\n        attention_weights = tf.reshape(attention_weights, (-1, ))\n\n        predicted_id = tf.argmax(predictions[0]).numpy()\n\n        result += targ_lang.index_word[predicted_id] + ' '\n\n        if targ_lang.index_word[predicted_id] == '<eos>':\n            return remove_tags(result), remove_tags(sentence)\n\n        # the predicted ID is fed back into the model\n        dec_input = tf.expand_dims([predicted_id], 0)\n\n    return remove_tags(result), remove_tags(sentence)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:30:49.725275Z","iopub.execute_input":"2023-08-16T10:30:49.725901Z","iopub.status.idle":"2023-08-16T10:30:49.736936Z","shell.execute_reply.started":"2023-08-16T10:30:49.725863Z","shell.execute_reply":"2023-08-16T10:30:49.735874Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"questions  =[]\nanswers = []\nwith open(\"../input/simple-dialogs-for-chatbot/dialogs.txt\",'r') as f :\n    for line in f :\n        line  =  line.split('\\t')\n        questions.append(line[0])\n        answers.append(line[1])\nprint(len(question) == len(answer))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:30:49.738443Z","iopub.execute_input":"2023-08-16T10:30:49.738951Z","iopub.status.idle":"2023-08-16T10:30:49.759729Z","shell.execute_reply.started":"2023-08-16T10:30:49.738916Z","shell.execute_reply":"2023-08-16T10:30:49.758585Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"def ask(sentence):\n    result, sentence = evaluate(sentence)\n\n    print('Question: %s' % (sentence))\n    print('Predicted answer: {}'.format(result))\nask(questions[100])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:30:49.761114Z","iopub.execute_input":"2023-08-16T10:30:49.761651Z","iopub.status.idle":"2023-08-16T10:30:49.857691Z","shell.execute_reply.started":"2023-08-16T10:30:49.761592Z","shell.execute_reply":"2023-08-16T10:30:49.856684Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Question: <sos> i believe so <eos>\nPredicted answer: good does it like <eos> \n","output_type":"stream"}]},{"cell_type":"code","source":"ask(questions[20])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:31:51.217121Z","iopub.execute_input":"2023-08-16T10:31:51.217506Z","iopub.status.idle":"2023-08-16T10:31:51.311879Z","shell.execute_reply.started":"2023-08-16T10:31:51.217474Z","shell.execute_reply":"2023-08-16T10:31:51.310786Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Question: <sos> it is not bad there are a lot of people there <eos>\nPredicted answer: good luck with that <eos> \n","output_type":"stream"}]},{"cell_type":"code","source":"print(answers[20])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:32:02.970935Z","iopub.execute_input":"2023-08-16T10:32:02.971331Z","iopub.status.idle":"2023-08-16T10:32:02.977251Z","shell.execute_reply.started":"2023-08-16T10:32:02.971299Z","shell.execute_reply":"2023-08-16T10:32:02.976197Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"good luck with that.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"ask(questions[10])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:32:25.216330Z","iopub.execute_input":"2023-08-16T10:32:25.216744Z","iopub.status.idle":"2023-08-16T10:32:25.263315Z","shell.execute_reply.started":"2023-08-16T10:32:25.216708Z","shell.execute_reply":"2023-08-16T10:32:25.262317Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Question: <sos> good luck with school <eos>\nPredicted answer: thanks <eos> \n","output_type":"stream"}]},{"cell_type":"code","source":"print(answers[10])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:32:19.451059Z","iopub.execute_input":"2023-08-16T10:32:19.451469Z","iopub.status.idle":"2023-08-16T10:32:19.457131Z","shell.execute_reply.started":"2023-08-16T10:32:19.451436Z","shell.execute_reply":"2023-08-16T10:32:19.456008Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"thank you very much.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}